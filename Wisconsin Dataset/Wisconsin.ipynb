{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c8207d6-7b71-498a-8253-d2ebac030e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d3fa1e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff38c0-d9c8-4b99-9597-f59927c7dc46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'ID': 230, 'type': 'NATIVE', 'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'venue': 'Electronic imaging', 'year': 1993, 'journal': None, 'DOI': '10.1117/12.148698', 'URL': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}\n",
      "                  name     role         type demographic description units  \\\n",
      "0                   ID       ID  Categorical        None        None  None   \n",
      "1            Diagnosis   Target  Categorical        None        None  None   \n",
      "2              radius1  Feature   Continuous        None        None  None   \n",
      "3             texture1  Feature   Continuous        None        None  None   \n",
      "4           perimeter1  Feature   Continuous        None        None  None   \n",
      "5                area1  Feature   Continuous        None        None  None   \n",
      "6          smoothness1  Feature   Continuous        None        None  None   \n",
      "7         compactness1  Feature   Continuous        None        None  None   \n",
      "8           concavity1  Feature   Continuous        None        None  None   \n",
      "9      concave_points1  Feature   Continuous        None        None  None   \n",
      "10           symmetry1  Feature   Continuous        None        None  None   \n",
      "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
      "12             radius2  Feature   Continuous        None        None  None   \n",
      "13            texture2  Feature   Continuous        None        None  None   \n",
      "14          perimeter2  Feature   Continuous        None        None  None   \n",
      "15               area2  Feature   Continuous        None        None  None   \n",
      "16         smoothness2  Feature   Continuous        None        None  None   \n",
      "17        compactness2  Feature   Continuous        None        None  None   \n",
      "18          concavity2  Feature   Continuous        None        None  None   \n",
      "19     concave_points2  Feature   Continuous        None        None  None   \n",
      "20           symmetry2  Feature   Continuous        None        None  None   \n",
      "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
      "22             radius3  Feature   Continuous        None        None  None   \n",
      "23            texture3  Feature   Continuous        None        None  None   \n",
      "24          perimeter3  Feature   Continuous        None        None  None   \n",
      "25               area3  Feature   Continuous        None        None  None   \n",
      "26         smoothness3  Feature   Continuous        None        None  None   \n",
      "27        compactness3  Feature   Continuous        None        None  None   \n",
      "28          concavity3  Feature   Continuous        None        None  None   \n",
      "29     concave_points3  Feature   Continuous        None        None  None   \n",
      "30           symmetry3  Feature   Continuous        None        None  None   \n",
      "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = breast_cancer_wisconsin_diagnostic.data.features\n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
    "\n",
    "\n",
    "# variable information\n",
    "print(breast_cancer_wisconsin_diagnostic.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "508f0721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Diagnosis\n",
      "0           M\n",
      "1           M\n",
      "2           M\n",
      "3           M\n",
      "4           M\n",
      "..        ...\n",
      "564         M\n",
      "565         M\n",
      "566         M\n",
      "567         M\n",
      "568         B\n",
      "\n",
      "[569 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe9c4c6-2a1a-4cdd-9c19-53bed38bb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.y = self.label_encoder.fit_transform(self.y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert X to tensor\n",
    "        X = torch.tensor(self.X.iloc[idx].values, dtype=torch.float32)\n",
    "        \n",
    "        y = torch.tensor(self.y[idx], dtype=torch.long)  # y is a Series, no need for DataFrame check\n",
    "        \n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "\n",
    "class CSVDataModule:\n",
    "    \"\"\"DataModule for loading CSV-like data (like UCI datasets).\"\"\"\n",
    "    def __init__(self, X, y, batch_size=64, test_size=0.2, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.test_size = test_size\n",
    "        self.transform = transform\n",
    "        self.train_data = None\n",
    "        self.val_data = None\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"Setup the training and validation datasets.\"\"\"\n",
    "        # Split the data into train and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(self.X, self.y, test_size=self.test_size)\n",
    "\n",
    "        # Normalize features (optional step)\n",
    "        scaler = StandardScaler()\n",
    "        X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "        X_val = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)\n",
    "\n",
    "        # Create datasets\n",
    "        self.train_data = MyDataset(X_train, y_train, transform=self.transform)\n",
    "        self.val_data = MyDataset(X_val, y_val, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"Return train DataLoader.\"\"\"\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        \"\"\"Return validation DataLoader.\"\"\"\n",
    "        return DataLoader(self.val_data, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d3ef53e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([64, 30]) torch.Size([64])\n",
      "torch.Size([7, 30]) torch.Size([7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\miniconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "csv_data_module = CSVDataModule(X,y)\n",
    "csv_data_module.setup()\n",
    "\n",
    "train_loader = csv_data_module.train_dataloader()\n",
    "val_loader = csv_data_module.val_dataloader()\n",
    "\n",
    "for batch_X, batch_y in train_loader:\n",
    "    print(batch_X.shape, batch_y.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0098536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dimension: 30\n"
     ]
    }
   ],
   "source": [
    "input_dim = batch_X.shape[1]\n",
    "print(f\"Input Dimension: {input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d371782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"Some Information about MyModule\"\"\"\n",
    "    def __init__(self, inputDim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.l1 = nn.Linear(inputDim,128)\n",
    "        self.l2 = nn.Linear(128,64)\n",
    "        self.output = nn.Linear(64,2)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "17b7f67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to the device\n",
    "model = SimpleModel(input_dim).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=20):\n",
    "    # loop over the dataset multiple times\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            # Move data to the device\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "    \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(batch_X)  # The model is already on the correct device\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print average loss per epoch\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d131907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.5735\n",
      "Epoch [2/100], Loss: 0.3471\n",
      "Epoch [3/100], Loss: 0.2325\n",
      "Epoch [4/100], Loss: 0.1277\n",
      "Epoch [5/100], Loss: 0.0903\n",
      "Epoch [6/100], Loss: 0.0700\n",
      "Epoch [7/100], Loss: 0.0667\n",
      "Epoch [8/100], Loss: 0.0528\n",
      "Epoch [9/100], Loss: 0.0503\n",
      "Epoch [10/100], Loss: 0.0458\n",
      "Epoch [11/100], Loss: 0.0765\n",
      "Epoch [12/100], Loss: 0.0656\n",
      "Epoch [13/100], Loss: 0.0375\n",
      "Epoch [14/100], Loss: 0.0383\n",
      "Epoch [15/100], Loss: 0.0523\n",
      "Epoch [16/100], Loss: 0.0347\n",
      "Epoch [17/100], Loss: 0.0276\n",
      "Epoch [18/100], Loss: 0.0261\n",
      "Epoch [19/100], Loss: 0.0240\n",
      "Epoch [20/100], Loss: 0.0226\n",
      "Epoch [21/100], Loss: 0.0220\n",
      "Epoch [22/100], Loss: 0.0205\n",
      "Epoch [23/100], Loss: 0.0336\n",
      "Epoch [24/100], Loss: 0.0188\n",
      "Epoch [25/100], Loss: 0.0202\n",
      "Epoch [26/100], Loss: 0.0167\n",
      "Epoch [27/100], Loss: 0.0148\n",
      "Epoch [28/100], Loss: 0.0143\n",
      "Epoch [29/100], Loss: 0.0132\n",
      "Epoch [30/100], Loss: 0.0125\n",
      "Epoch [31/100], Loss: 0.0110\n",
      "Epoch [32/100], Loss: 0.0103\n",
      "Epoch [33/100], Loss: 0.0103\n",
      "Epoch [34/100], Loss: 0.0089\n",
      "Epoch [35/100], Loss: 0.0120\n",
      "Epoch [36/100], Loss: 0.0077\n",
      "Epoch [37/100], Loss: 0.0074\n",
      "Epoch [38/100], Loss: 0.0065\n",
      "Epoch [39/100], Loss: 0.0076\n",
      "Epoch [40/100], Loss: 0.0057\n",
      "Epoch [41/100], Loss: 0.0059\n",
      "Epoch [42/100], Loss: 0.0058\n",
      "Epoch [43/100], Loss: 0.0049\n",
      "Epoch [44/100], Loss: 0.0045\n",
      "Epoch [45/100], Loss: 0.0041\n",
      "Epoch [46/100], Loss: 0.0038\n",
      "Epoch [47/100], Loss: 0.0035\n",
      "Epoch [48/100], Loss: 0.0039\n",
      "Epoch [49/100], Loss: 0.0032\n",
      "Epoch [50/100], Loss: 0.0030\n",
      "Epoch [51/100], Loss: 0.0028\n",
      "Epoch [52/100], Loss: 0.0027\n",
      "Epoch [53/100], Loss: 0.0026\n",
      "Epoch [54/100], Loss: 0.0025\n",
      "Epoch [55/100], Loss: 0.0023\n",
      "Epoch [56/100], Loss: 0.0022\n",
      "Epoch [57/100], Loss: 0.0026\n",
      "Epoch [58/100], Loss: 0.0021\n",
      "Epoch [59/100], Loss: 0.0020\n",
      "Epoch [60/100], Loss: 0.0056\n",
      "Epoch [61/100], Loss: 0.0024\n",
      "Epoch [62/100], Loss: 0.0020\n",
      "Epoch [63/100], Loss: 0.0018\n",
      "Epoch [64/100], Loss: 0.0020\n",
      "Epoch [65/100], Loss: 0.0016\n",
      "Epoch [66/100], Loss: 0.0018\n",
      "Epoch [67/100], Loss: 0.0015\n",
      "Epoch [68/100], Loss: 0.0014\n",
      "Epoch [69/100], Loss: 0.0013\n",
      "Epoch [70/100], Loss: 0.0013\n",
      "Epoch [71/100], Loss: 0.0012\n",
      "Epoch [72/100], Loss: 0.0012\n",
      "Epoch [73/100], Loss: 0.0011\n",
      "Epoch [74/100], Loss: 0.0010\n",
      "Epoch [75/100], Loss: 0.0010\n",
      "Epoch [76/100], Loss: 0.0009\n",
      "Epoch [77/100], Loss: 0.0009\n",
      "Epoch [78/100], Loss: 0.0010\n",
      "Epoch [79/100], Loss: 0.0009\n",
      "Epoch [80/100], Loss: 0.0010\n",
      "Epoch [81/100], Loss: 0.0011\n",
      "Epoch [82/100], Loss: 0.0008\n",
      "Epoch [83/100], Loss: 0.0008\n",
      "Epoch [84/100], Loss: 0.0007\n",
      "Epoch [85/100], Loss: 0.0009\n",
      "Epoch [86/100], Loss: 0.0007\n",
      "Epoch [87/100], Loss: 0.0007\n",
      "Epoch [88/100], Loss: 0.0006\n",
      "Epoch [89/100], Loss: 0.0006\n",
      "Epoch [90/100], Loss: 0.0006\n",
      "Epoch [91/100], Loss: 0.0006\n",
      "Epoch [92/100], Loss: 0.0006\n",
      "Epoch [93/100], Loss: 0.0005\n",
      "Epoch [94/100], Loss: 0.0007\n",
      "Epoch [95/100], Loss: 0.0007\n",
      "Epoch [96/100], Loss: 0.0005\n",
      "Epoch [97/100], Loss: 0.0006\n",
      "Epoch [98/100], Loss: 0.0005\n",
      "Epoch [99/100], Loss: 0.0005\n",
      "Epoch [100/100], Loss: 0.0005\n"
     ]
    }
   ],
   "source": [
    "train_model(model,train_loader,criterion,optimizer,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "764d1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No gradients needed for evaluation\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            # Move inputs and labels to the correct device\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            \n",
    "            # Get the predicted class\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Update total and correct counts\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "467b4396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.25%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, val_loader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507bdae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
